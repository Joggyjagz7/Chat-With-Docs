{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u3r6Gs0I2vJ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "!pip install ollama\n",
        "!pip install colab-xterm\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install newsapi-python\n",
        "!pip install jq\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLu-jgdnLRhG"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "import ollama\n",
        "\n",
        "# Load documents from a JSON file\n",
        "def load_documents(file_path):\n",
        "    \"\"\"\n",
        "    Loads documents from a JSON file using a predefined schema.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): The path to the JSON file containing the documents.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of documents loaded from the file.\n",
        "    \"\"\"\n",
        "    loader = JSONLoader(file_path=file_path, jq_schema='.[] | { description: .description, url: .url}', text_content=False)\n",
        "    return loader.load()\n",
        "\n",
        "# Split documents into manageable chunks\n",
        "def split_documents(documents):\n",
        "    \"\"\"\n",
        "    Splits documents into smaller chunks to manage processing load.\n",
        "\n",
        "    Parameters:\n",
        "    documents (list): A list of documents to be split.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of split document chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "# Create embeddings and vector store\n",
        "def create_vector_store(documents):\n",
        "    \"\"\"\n",
        "    Creates a vector store from document embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    documents (list): A list of documents or text chunks.\n",
        "\n",
        "    Returns:\n",
        "    VectorStore: A vector store containing the documents' embeddings.\n",
        "    \"\"\"\n",
        "    embedding_model = OllamaEmbeddings(model=\"llama3\")\n",
        "    vector_store = Chroma.from_documents(documents=documents, embedding=embedding_model)\n",
        "    return vector_store.as_retriever()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7YlC_9KLUwd"
      },
      "outputs": [],
      "source": [
        "from newsapi import NewsApiClient\n",
        "import json\n",
        "\n",
        "#Paste your Api key\n",
        "newsapi = NewsApiClient(api_key='')\n",
        "\n",
        "def latest_news(data):\n",
        "    try:\n",
        "        all_articles = newsapi.get_everything(q=data, language='en', sort_by='publishedAt')\n",
        "        extracted_data = []\n",
        "        k=0\n",
        "        for article in all_articles['articles']:\n",
        "            if k>8:\n",
        "                break\n",
        "            extracted_data.append({\n",
        "                'description': article.get('description', 'No description available'),\n",
        "                'url': article.get('url', 'No Url')\n",
        "                        })\n",
        "        with open('news.json', 'w') as p:\n",
        "            json.dump(extracted_data, p)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fetch news articles: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuz-HG0AI9NN"
      },
      "outputs": [],
      "source": [
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fnk26bc6WAk0"
      },
      "outputs": [],
      "source": [
        "# Enter \"Ollama Serve\" command below\n",
        "# This will start a ollama server\n",
        "%xterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHO__tb5qHt-"
      },
      "outputs": [],
      "source": [
        "# Enter \"Ollama run llam3\" command below\n",
        "# This will download llama3 and run it on ollama server\n",
        "%xterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtKSv1g9LeZW"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "def generate_newsletter(topic):\n",
        "    latest_news(topic)\n",
        "    question = f\"\"\"\n",
        "        # Your Daily Digest: {date.today()}\n",
        "\n",
        "        Welcome to your curated news update, bringing you the latest and most relevant headlines directly to your inbox.\n",
        "\n",
        "        ## Today's Top Story\n",
        "        ### [Title of the Main News Article](URL_to_article)\n",
        "        Provide a brief introduction to the top story of the day, emphasizing the main points succinctly.\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## More News\n",
        "\n",
        "        ### [Second News Article Title](URL_to_second_article)\n",
        "        **Summary**: Offer a concise summary of the second most important news of the day.\n",
        "\n",
        "        ### [Third News Article Title](URL_to_third_article)\n",
        "        **Summary**: Summarize this article, highlighting key details that inform the reader effectively.\n",
        "\n",
        "        ### [Fourth News Article Title](URL_to_fourth_article)\n",
        "        **Summary**: Briefly cover the fourth article, focusing on crucial points.\n",
        "\n",
        "        ### [Fifth News Article Title](URL_to_fifth_article)\n",
        "        **Summary**: Sum up the fifth article, ensuring to pinpoint essential information.\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Instructions**:\n",
        "        - Write a news summary for the topic: '{topic}'.\n",
        "        - Ensure the news summaries do not repeat information.\n",
        "        - Follow the structure provided above as a template for the news summary.\n",
        "        \"\"\"\n",
        "    documents = load_documents('news.json')\n",
        "    document_splits = split_documents(documents)\n",
        "    retriever = create_vector_store(document_splits)\n",
        "\n",
        "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retriever.invoke(topic))\n",
        "    formatted_prompt = f\"Question: {question}\\n\\nContext: {formatted_context}\"\n",
        "    llm_response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
        "    return llm_response['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNx6RZyPbF3s"
      },
      "outputs": [],
      "source": [
        "#Enter the topic for the news below\n",
        "newsletter = generate_newsletter('World News')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1iDFm-0OYp4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(newsletter))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}